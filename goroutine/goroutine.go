package main

import (
	"fmt"
	"sync"
)

func main() {

	//ТЕОРИЯ

	/*
		КОМПЬЮТЕР (OS)

		Процессор может выполнять ОДНОВРЕМЕННО несколько действий, только если у него несколько ядер.
		Но при этом даже если ядро одно - он может выполнять несколько задач, переключаясь между ними
		так быстро, что нам кажется, что они выполняются одновременно (но в один момент времени при этом
		выполняется один процесс).

		Конкурентность (Concurrency) - это дизайн программы. Когда у нас есть несколько процессов, которые
		могут выполняться независимо друг от друга, не важно в каком порядке (когда мы работаем со множеством
		вещей одновременно).
		Параллельность (Parallelism) — это уже про выполнение программы, а именно — выполнение нескольких задач
		в один момент времени (когда выполняем множество вещей одновременно).

		Поток (тред) - это последовательность команд, которые выполняются в рамках одного процесса (это та работа,
		которая выполняется на процессоре, либо ждёт своей очереди). У треда три состояния:
			1) Executing: выполняется прямо сейчас на одном из ядер
			2) Runnable: готов к выполнению, дожидается своей очереди
			3) Waiting: не готов к выполнению, так как ждёт какого-то события. Например, это может быть связано с i/o
			операцией, взаимодействием с ОС (syscall) и др.

		Переключение контекста (context switching) - планировщик ОС может в любой момент времени переключать треды
		(отключать выполняющиеся от ядра процессора и заменять ил Runnable тредами). Этот подход называется
		вытесняющей многозадачностью (preemptive multitasking).

		1) переключение контекста занимает много времени (нужно обновить данные в кэшах процессора, сохранить состояние
		треда и др.). Чем больше у нас тредов в состоянии Runnable, тем чаще будет переключаться контекст, и тем медленнее
		будет работать программа. К примеру, если переключений слишком много, то всем они суммарно могут занимать столько
		же времени, сколько само выполнение задач (а то и больше).
		2) занимает много памяти - стек каждого треда часто может занимать до пары мегабайт (в нём хранятся локальные
		переменные, цепочки вызова функций и др.).
		У тредов дорого и создание, и удаление, и само существование.

		KERNEL SPACE - пространство ядра
		USER SPACE - пространство пользователя
		Планирование потоков на уровне kernel space, то есть ими управляет ОС



		ПЛАНИРОВЩИК GO

		Планировщик - управляет горутинами.

		Горутина - аналог треда (потока), но не на уровне ОС, а внутри GO (внутри программы), при этом более
		легковесный. Планирование горутин происходит на уровне user space, то есть ими управляет планировщик
		GO (Go Runtime). По сути они нужны чтобы более эффективно использовать ресурсы системных потоков. Они
		работают эффективнее потому что - переключение между ними дешево (без участия ОС), у них общий доступ
		к памяти.

		У горутины есть три состояния:
		1) Waiting — горутина не готова к запуску, так как чего-то ждёт
		2) Runnable — готова к запуску, как только освободится тред
		3) Executing — выполняется на каком-то треде

		Машина для выполнения (M, Machine) — будет непосредственно выполнять горутину (это системный поток).
		Процессор (P, Processor) — будет помещать горутины (G) в Машину (то есть просто привязывать к потоку).

		Go приложение имеет размер пула потоков (количество потоков), на котором он работает:
		РАЗМЕР ПУЛА = КОЛИЧЕСТВО ДОСТУПНЫХ ЯДЕР (ещё больше тредов нет смысла, ведь тогда часть из них точно
		будет простаивать в ожидании свободного ядра, меньше - ядра будут простаивать).
		runtime.GOMAXPROCS() задает размер пула (получить текущее - n := runtime.GOMAXPROCS(0)).



		ЭЛЕМЕНТЫ МЕХАНИЗМА ПЛАНИРОВЩИКА

		1) GRQ (GLOBAL RUN QUEUE)
		- глобальная очередь, куда попадают горутины в состоянии Runnable.

		2) КАЖДЫЙ ПОТОК:
		- приставлен свой собственный процессор, он постоянно ищет задачи и передает их в поток. Если в его локальной
		очереди задач нет - ворует их у других процессоров, либо берет из GRQ, либо из NETPOLLER.
		- есть LRQ (local run queue) - тут лежат горутины в состоянии Runnable. LRQ нужна для того, чтобы избавиться
		от блокировок. Если бы у всех процессоров была одна очередь - им пришлось бы ее блокировать, чтобы взять
		оттуда задачу (чтобы одну и ту же не взяли сразу два процессора), из-за этого это бы работало очень медленно.
		- сам поток - там находится горутина в состоянии Running.

		3) HANDOFF
		горутина может вызвать какую-то блокирующую долгую операцию (syscall - системный вызов). Если этот системный
		вызов не может работать асинхронно (если может - отправится в NETPOLLER) - тогда заблокируется горутина, процессор
		и сам системный тред. Вступает в силу handoff - он отвязывает тред от процессора, создает другой и привязывает
		его к процессору. Когда системный вызов закончил свою работу - он либо возвращает горутину тому процессору, от
		которого он его отвязал (если тот свободен), либо другому процессору (если нашел свободный), в ином случае
		отправляет в GRQ.

		4) SYSMON
		- механизм оптимизации при syscall, чтобы не создавать втупую каждый раз новый поток при любом синхронном системном
		вызове. Сам по себе занимает целый поток, постоянно выполняется фоном. В его обязанности входит оптимизация:
			- если мы знаем, что системный вызов надолго заболкирует тред, то сразу выполним handoff.
			- в иных случаях позволим треду оставаться в заблокированном состоянии, мониторя, не освободился ли
			он. Если он превысит таймаут в 10 ms, то мы запускаем handoff.
			- устанавливает горутине флаг, что она работает слишком долго, чтобы та прервалась.
			- мониторит каждые 10 секунд NETPOLLER, если в него никто не заглядывал более 10ms - то отправляет его горутины
			в состоянии Runnable в GRQ.

		5) NETPOLLER (network poller)
		- ОС предоставляет механизмы для выполнения асинхронных системных вызовов, с помощью которых можно обойти блокировку
		при системном вызове - epoll (Linux), kqueue (MacOS, BSD), IOCP (Windows). Эти механизмы позволяют сделать так:
			1) Тред инициирует системный вызов и идёт по другим своим делам. Системный вызов будет зарегистрирован в
			специальной системе, и мы сможем вернуться к нему позже.
			2) Периодически проверяем, не пришел ли ответ для системного вызова.
		НЕ ВСЕ SYSCALL МОГУТ ВЫПОЛНЯТЬСЯ АСИНХРОННО.
		В network poller регистрируются те системные вызовы, которые могут выполняться асинхронно. Горутина переводится
		в состояние Waiting и передается сюда. Процессор освобождается для выполнения других горутин.

		Для I/O операций с сетью можно смело использовать горутины — они будут эффективно обрабатываться через netpoller
		(тут тоже есть свои ограничения, но другие).
		// Это будет работать через netpoller
		conn, _ := net.Dial("tcp", "example.com:80")
		data, _ := conn.Read(buf)

		Для операций с файлами нужно быть намного аккуратнее, так как они будут блокировать треды.
		// А это заблокирует тред
		file, _ := os.Open("bigfile.dat") data, _ := file.Read(buf)

		Когда горутины дождались своих syscall, они все еще сидят тут в состоянии Runnable и ждут пока их заберут либо
		сами процессоры, либо если никто сюда не обращался более 10ms (Sysmon мониторит это в фоне), то освободившиеся
		горутины будут отправлены в GRPQ.



		АЛГОРИТМ ПОИСКА ЗАДАЧ ПРОЦЕССОРОМ

		1) 1/61 раз проверяем GRQ, и если там есть горутины, то берём оттуда.
		- GRQ стоит проверять, чтобы горутины там не застаивались.
		- 1/61 - потому что это простое число и и это помогает избежать синхронизации проверок между разными P, распределяя
		их более равномерно. Еще - это число не слишком большое и не слишком маленькое, поэтому проверки будут не слишком
		частыми и не слишком редкими.

		2) Если нет, проверяем LRQ
		- проверяем свою локальную очередь

		3) Если там нет, пытаемся украсть у другого Процессора
		- чтобы задачи не застаивались у одного процессора, когда второй полностью свободен. При этом забирает он не одну
		задачу, а сразу половину (чтобы потом не пришлось ходить еще раз).

		4) Если не получилось, проверяем GRQ
		- в итоге задачи нигде не нашлись, просто берем их из GRQ

		5) Проверяем Network Poller
		- ищет у него горутины в состоянии Runnable, чтобы забрать их в работу. Это как раз те горутины, которые дождались
		своих syscall. При этом может быть проблема, что у процессоров работы хватает и они вообще никогда не дойдут до
		этого шага, поэтому Sysmon в фоне мониторит - если никто сюда не обращался более 10ms, то освободившиеся горутины
		полетят в GRPQ.



		ВЫТЕСНЕНИЕ ГОРУТИН

		Так как бывают долгоживущие или вечные горутины - предоставлять им процессорное время навсегда -
		плохая идея. Так мы не доберемся до других горутин никогда и заблокируем поток. Поэтому есть механизм
		остановки горутины. Существует два способа вытеснения горутин:

		1) ОСНОВНОЙ СПОСОБ - через проверку stackguard в безопасных точках. Горутина сама решает когда остановиться:

			1) когда горутина проверяет, нужно ли ей остановиться?
			Она выполняет эти проверки в безопасные моменты для вытеснения:
				1) Перед вызовом функций (пролог): Когда функция вызывается, создаётся фрейм стека (выделенная область
				в памяти, где хранятся локальные переменные, адрес возврата и другие данные функции). При прерывании в
				момент вызова функции вся нужная информация уже сохранена во фрейме, поэтому горутину можно приостановить
				без риска потерять данные. При возобновлении выполнения горутина начнёт с этого вызова функции, используя
				те же значения переменных.
				2) При совершении блокирующих операций (наши любимые syscall'ы, таймеры и прочее): в эти моменты горутина
				всё равно будет ждать и простаивать, поэтому пусть поработает кто-то другой.

			2) как горутина понимает, что нужно остановиться?
			Чтобы горутине понять, что ей пора уступить - существует флаг stackguard. Когда нужно прервать горутину,
			этому флагу можно установить значение stackPreempt

			3) кто будет сообщать горутине, что ей нужно остановиться?
			SYSMON будет устанавливать горутине флаг stackguard со значением stackPreempt, если она выполняется больше
			10 ms.



		2) ЗАПАСНОЙ СПОСОБ — через сигналы операционной системы, если горутина не хочет останавливаться сама:

			Проблема "жадной горутины", решение этой проблемы в Go v1.14:

			func main() {
				// Устанавливаем количество процессоров = 1
				runtime.GOMAXPROCS(1)

				// запускаем "жадную" горутину, которая захватит процессор
				go func() {
					sum := 0
					for {
						sum++ // бесконечный цикл без вызовов функций
					}
				}()

				// Запускаем time.Sleep, чтобы передать управление жадной горутине
				// и не выйти раньше времени из main()
				time.Sleep(time.Second)
			}

			Горутина заблокировала весь процессор, и не может его отдать. Она не вызывает функции, а значит не проверяет
			stackguard, она не выполняет блокирующие операции, она просто ворует все ресурсы, и наш Sysmon ничего не может
			с этим поделать.

			Поэтому в обновлении 1.14 решили эту проблему:
			если горутина не передает управление больше 10ms добровольно, то ей отправляется сигнал SIGURG и она прерывается
			принудительно.



		https://habr.com/ru/articles/891426/


	*/

	//КОД

	//1) зачем нужны горутины?

	// downloadFile1 := func(filename string) {
	// 	fmt.Printf("Starting download: %s\n", filename)
	// 	// Simulate file download with sleep
	// 	time.Sleep(2 * time.Second)
	// 	fmt.Printf("Finished download: %s\n", filename)
	// }

	// fmt.Println("Starting downloads...")

	// startTime := time.Now()

	// downloadFile1("file1.txt")
	// downloadFile1("file2.txt")
	// downloadFile1("file3.txt")

	// elapsedTime := time.Since(startTime)

	// fmt.Printf("All downloads completed! Time elapsed: %s\n", elapsedTime)

	// Starting downloads...
	// Starting download: filel.txt
	// Finished download: filel.txt
	// Starting download: file2.txt
	// Finished download: file2.txt
	// Starting download: file3.txt
	// Finished download: file3.txt
	// All downloads completed! Time elapsed: 6s
	// Program exited.

	/*

		0s        2s        4s        6s
		|---------|---------|---------|
		| file1   | file2   | file3   |
		| .txt    | .txt    | .txt    |
		| (2s)    | (2s)    | (2s)    |
		|---------|---------|---------|

		выполнение очень медленное, так как все задачи выполнялись последовательно и выполнились за t*n время (t - время
		выполнения одной задачи, n - количество задач). Можно это ускорить с помощью горутин, запустив их параллельно.
	*/

	fmt.Println("----------------------------------------------------------------------------------------------")

	// fmt.Println("Starting downloads...")

	// startTime := time.Now()

	// go downloadFile1("file1.txt")
	// go downloadFile1("file2.txt")
	// go downloadFile1("file3.txt")

	// elapsedTime := time.Since(startTime)

	// fmt.Printf("All downloads completed! Time elapsed: %s\n", elapsedTime)

	// Starting downloads...
	// All downloads completed!
	// Program exited.

	/*
		Вывелось не все, потому что main завершилась до того, как горутины отработали. Фукнция main - тоже горутина.
	*/

	fmt.Println("----------------------------------------------------------------------------------------------")

	//2) wait group
	/*
		для управления конкурентностью в го применяется `sync.WaitGroup`, благодаря wg можно ожидать завершение горутин.

		1) WaitGroup инициализирует внутренний счетчик
		2) wg.Add(n) увеличивает счетчик на n
		3) wg.Done() уменьшает счетчик на 1
		4) wg.Wait() блокирует main до тех пор пока счетчик не станет 0


		эти две строчки эквивалентны:
		var wg sync.WaitGroup
		wg := sync.WaitGroup{}

		так как когда в go мы объявляем переменную с каким-то типом, она становится равна default значению для этого типа
		("" для string и тд), поэтому в первом случае он инициализирует его нулевым состоянием, готовым к использованию.

	*/

	// downloadFile2 := func(filename string, wg *sync.WaitGroup) {
	// 	// Сообщим wg о том что мы закончили перед выходом из функции
	// 	defer wg.Done()

	// 	fmt.Printf("Starting download: %s\n", filename)
	// 	time.Sleep(2 * time.Second)
	// 	fmt.Printf("Finished download: %s\n", filename)
	// }

	// fmt.Println("Starting downloads...")

	// var wg sync.WaitGroup

	// // Сообщим wg что мы собираемся запускать 3 горутины
	// wg.Add(3)

	// go downloadFile2("file1.txt", &wg)
	// go downloadFile2("file2.txt", &wg)
	// go downloadFile2("file3.txt", &wg)

	// // Ждем завершения всех горутин
	// wg.Wait()

	// fmt.Println("All downloads completed!")

	// Starting downloads...
	// Starting download: file3.txt
	// Starting download: filel.txt
	// Starting download: file2.txt
	// Finished download: file3.txt
	// Finished download: filel.txt
	// Finished download: file2.txt
	// All downloads completed!
	// Program exited.

	/*
		1) main вызывает add(3) до запуска горутин
		2) Каждая горутина вызывает Done() по завершению функции (defer wg.Done())
		3) main блокируется до тех пор пока счетчик wait() не станет 0
		4) Когда счетчик становится равным 0, блокировка main снимается и программа может завершаться
	*/

	/*
		// ТАК ДЕЛАТЬ НЕЛЬЗЯ
		go downloadFile("file1.txt", &wg)
		wg.Add(1)  // Нарушен порядок!

		// ТАК ДЕЛАТЬ НЕЛЬЗЯ
		wg.Add(2)  // Нарушен счетчик
		go downloadFile("file1.txt", &wg)
		go downloadFile("file2.txt", &wg)
		go downloadFile("file3.txt", &wg)

		// ТАК ДЕЛАТЬ НЕЛЬЗЯ
		func downloadFile(filename string, wg *sync.WaitGroup) {
			// не указан wg.Done()
			fmt.Printf("Downloading: %s\n", filename)
		}
	*/

	fmt.Println("----------------------------------------------------------------------------------------------")

	//3) как горутинам обмениваться информацией?
	/*
		горутины могут обмениваться информацией через каналы. Каналы это мощные примитивы взаимодействия между горутинами
		предоставляющий возможность безопасного обмена данными.

		вот некоторые свойства каналов

		1) Каналы это блокировки по своей сути
		2) Запись в канал ch <- value  блокирует main пока другая горутина не прочтет из канала.
		3) Чтение из канала <-ch блокирует main пока другая горутина не запишет из канал
	*/

	// downloadFile3 := func(filename string, done chan bool) {
	// 	fmt.Printf("Starting download: %s\n", filename)
	// 	time.Sleep(2 * time.Second)
	// 	fmt.Printf("Finished download: %s\n", filename)

	// 	done <- true // отправляем сигнал о завершении
	// }

	// fmt.Println("Starting downloads...")

	// startTime := time.Now()

	// // создаем канал для отслеживания статуса горутин
	// done := make(chan bool)

	// go downloadFile3("file1.txt", done)
	// go downloadFile3("file2.txt", done)
	// go downloadFile3("file3.txt", done)

	// // Ждем пока все горутины сигнализируют о закрытии
	// for i := 0; i < 3; i++ {
	// 	<-done // Получаем сигнал от каждой завершенной горутины
	// }

	// elapsedTime := time.Since(startTime)
	// fmt.Printf("All downloads completed! Time elapsed: %s\n", elapsedTime)

	fmt.Println("----------------------------------------------------------------------------------------------")

	//4) mutex
	/*
		Что делать, если у нас есть несколько экземпляров горутины, влияющие на одну переменную?
	*/

	var x int
	wg1 := new(sync.WaitGroup)

	for i := 0; i < 1000; i++ {
		// Запускаем 1000 экземпляров горутины, увеличивающей счетчик на 1
		wg1.Add(1)
		go func(wg1 *sync.WaitGroup) {
			defer wg1.Done()
			x++
		}(wg1)
	}

	wg1.Wait()

	// По идее значение счетчика должно быть 1000, но крайне вероятно, что этого не произойдет
	fmt.Println(x) //случайной значение, < 1000

	/*
		Первая горутина получает значение переменной x, а вторая одновременно с этим делает то же самое. В результате
		обе горутины считают, что x = 0, и обе присваивают ему значение = 1 (0 + 1). Получается, что мы наткнулись на
		эффект "грязного чтения". Чтобы заблокировать это значение существуют мьютексы.

		В Go мьютексы (sync.Mutex) используются для синхронизации доступа к разделяемым данным, чтобы избежать гонки
		данных (data race) при выполнении конкурентного кода (например, с использованием горутин). В Go (и вообще в
		многопоточном программировании), мьютексы блокируют не доступ к переменной или функции напрямую, а управляют
		доступом к критической секции кода, в которой работает с этими переменными.

		Он блокирует код, который ты сам обернул в mu.Lock() и mu.Unlock(). Если другая горутина зашла в область кода,
		которая залочена - он будет ждать, пока она разлочится.

		Кстати, под капотом у каналов - мьютексы, так что мьютексы работают быстрее каналов в любом случае.
	*/

	var y int
	wg2 := new(sync.WaitGroup)
	mu := new(sync.Mutex)

	for i := 0; i < 1000; i++ {
		// Запускаем 1000 экземпляров горутины, увеличивающей счетчик на 1
		wg2.Add(1)
		go func(wg2 *sync.WaitGroup, mu *sync.Mutex) {
			defer wg2.Done()
			mu.Lock() //заблокировали
			y++       // теперь они не смогут одновременно получить доступ к этой переменной
			mu.Unlock()
		}(wg2, mu)
	}

	wg2.Wait()
	fmt.Println(y) //1000

	//реализовать то же самое с использованием каналов
	var z int
	wg3 := new(sync.WaitGroup)
	channel := make(chan bool, 1)

	channel <- true

	for i := 0; i < 1000; i++ {
		wg3.Add(1)
		go func(wg3 *sync.WaitGroup) {
			defer wg3.Done()
			<-channel
			z++
			channel <- true
		}(wg3)
	}

	wg3.Wait()
	fmt.Println(z) //1000

	/*
		у нас забитый канал размером 1. При заходе в первую горутину он может прочитать значение, забирает его
		(параллельные другие горутины пока не могут прочитать, так как канал пустой, и ждут пока там что-то
		появится). Далее мы инкрементируем значение (или выполняем любой другой конкуретный код), затем кладем
		значение в канал снова. Любая другая горутина его ловит (одна) и все повторяется по кругу.
	*/

	fmt.Println("----------------------------------------------------------------------------------------------")

	//5) с циклами
	N := 10

	//неправильный вариант, когда берем значение, которое УЖЕ поменялось
	first := func() {
		m := make(map[int]int)

		wg := &sync.WaitGroup{}
		mu := &sync.Mutex{}
		wg.Add(N)

		for i := 0; i < N; i++ {
			go func() {
				defer wg.Done()
				mu.Lock()
				m[i] = i //берет ссылку на i, а не копию. К этому моменту i может уже измениться, поэтому многие i мы пропустим!
				mu.Unlock()
			}()
		}

		wg.Wait()
		fmt.Println(len(m)) //выведет < 10
	}

	//правильный вариант, берем копию значения, поэтому нам уже неважно, поменялось оно или нет
	second := func() {
		m := make(map[int]int)

		wg := &sync.WaitGroup{}
		mu := &sync.Mutex{}
		wg.Add(N)

		for i := 0; i < N; i++ {
			go func(i int) {
				defer wg.Done()
				mu.Lock()
				m[i] = i
				mu.Unlock()
			}(i)
		}

		wg.Wait()
		fmt.Println(len(m)) //все верно - 10
	}

	first()
	second()

	fmt.Println("----------------------------------------------------------------------------------------------")

}
